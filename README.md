# pytorch NLP入门  复现一些NLP论文/传统机器学习算法

## contributors


## 要求
- 代码风格统一，函数不冗余，尽量使用官方工具函数，在保持原生态实现的情况下尽量保持代码的精简，库版本统一
- 代码注释齐全，重要部分注明论文出处和公式来源
- 测试数据集下载方便，方便运行，不用在环境搭建上花费太多时间

## 实现

## 第一章 Word2Vec's SkipGram NegativeSampling
- skip-gram
- 负样本采样 negative sampling 	[论文](https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf)
## 第二章 lstm
- lstm
- lstm + attention
## 第三章 attention
- [Attention is All you need](https://arxiv.org/pdf/1706.03762.pdf)

